{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n",
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Check if proper versions are used\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization & Scaling Functions using Numpy & Pandas\n",
    "\n",
    "# Outlier Scaling using .quantile() Pandas methods\n",
    "def scale_outlier(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    min_bound = Q1 - 1.5*IQR\n",
    "    max_bound = Q3 + 1.5*IQR\n",
    "    df[column] = np.where(df[column] > max_bound, max_bound, df[column])\n",
    "    df[column] = np.where(df[column] < min_bound, min_bound, df[column])\n",
    "\n",
    "# Min-Max Scaling using .min() and .max() Pandas methods\n",
    "def min_max_scaling(df):    \n",
    "    df_norm = df.copy()\n",
    "    for column in df_norm.columns:\n",
    "        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())        \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset using Pandas\n",
    "df = pd.read_csv(\"LBW_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Drop the columns Delivery Phase(1: 90, 2: 2, NaN: 4) and Education(5: 93, NaN: 3)\n",
    "df = df.drop([\"Delivery phase\", \"Education\"], axis = 1)\n",
    "\n",
    "# Not sure if this is Proper, what if testing set has Community = 2?\n",
    "# Replacing Community = 2(count = 1) with Community = 1\n",
    "df[\"Community\"] = np.where(df[\"Community\"] == 2, 1, df[\"Community\"])\n",
    "\n",
    "# Replacing Nan of Weights with the Mean of its respective Result category\n",
    "mean_0 = (df.loc[df['Result'] == 0])['Weight'].mean()\n",
    "mean_1 = (df.loc[df['Result'] == 1])['Weight'].mean()\n",
    "\n",
    "df[\"Weight\"] = np.where((df[\"Result\"] == 0) & (df[\"Weight\"].isna()), mean_0, df[\"Weight\"])\n",
    "df[\"Weight\"] = np.where((df[\"Result\"] == 1) & (df[\"Weight\"].isna()), mean_1, df[\"Weight\"])\n",
    "\n",
    "# For now, Filling Numeric Columned NaN Values with Mean\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "df[\"HB\"] = df[\"HB\"].fillna(df[\"HB\"].mean())\n",
    "df[\"BP\"] = df[\"BP\"].fillna(df[\"BP\"].mean())\n",
    "# df[\"Weight\"] = df[\"Weight\"].fillna(df[\"Weight\"].mean()) -> cleaned using the above method\n",
    "\n",
    "# Very Basic Method of taking care of Outliers(Replace with IQR, Min-Max) for Age & BP columns\n",
    "scale_outlier(df, \"Age\")\n",
    "scale_outlier(df, \"BP\")\n",
    "\n",
    "# Labelling Residence = 2 as Residence = 0 to get Binary Labelled Column (Before: Residence(1,2), After: Residence(1,0))\n",
    "df[\"Residence\"] = np.where(df[\"Residence\"] == 2, 0, df[\"Residence\"])\n",
    "# Filling NaN with Mode = 1\n",
    "df[\"Residence\"] = df[\"Residence\"].fillna(1)\n",
    "\n",
    "# One-Hot-Encode Community(1,3,4) to Community_1(1,0), Community_3(1,0), Community_4(1,0)\n",
    "df = pd.get_dummies(df, columns=[\"Community\"], dtype = float)\n",
    "#df = df.drop([\"Community\"], axis = 1)\n",
    "\n",
    "# Converting IFA(int) to IFA(float)\n",
    "df[\"IFA\"] = df[\"IFA\"].astype(float)\n",
    "\n",
    "# Moving converted Float Result, to get it as the last Column\n",
    "res = df[\"Result\"].astype(float)\n",
    "df = df.drop([\"Result\"], axis = 1)\n",
    "df[\"Result\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Normalization of the dataset (into ranges from 0 to 1) using Pandas\n",
    "df = min_max_scaling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>HB</th>\n",
       "      <th>IFA</th>\n",
       "      <th>BP</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Community_1</th>\n",
       "      <th>Community_3</th>\n",
       "      <th>Community_4</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.293194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.478632</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age    Weight        HB  IFA        BP  Residence  Community_1  \\\n",
       "0  0.273504  0.342857  0.647059  1.0  0.171030        1.0          1.0   \n",
       "1  0.273504  0.171429  0.568627  1.0  0.293194        1.0          1.0   \n",
       "2  0.273504  0.171429  0.647059  1.0  0.904014        1.0          1.0   \n",
       "3  0.273504  0.171429  0.411765  1.0  0.171030        1.0          1.0   \n",
       "4  0.478632  0.085714  0.666667  1.0  0.362583        1.0          1.0   \n",
       "\n",
       "   Community_3  Community_4  Result  \n",
       "0          0.0          0.0     0.0  \n",
       "1          0.0          0.0     0.0  \n",
       "2          0.0          0.0     0.0  \n",
       "3          0.0          0.0     0.0  \n",
       "4          0.0          0.0     0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train-Test Splits of the dataset using .train_test_split() in Sklearn\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "  return 1/(np.exp(-Z)+1)\n",
    "def relu(Z):\n",
    "  return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(dims):\n",
    "  parameters={}\n",
    "  for l in range(1,len(dims)):\n",
    "    parameters[\"W\"+ str(l)]=np.random.randn(dims[l],dims[l-1])*np.sqrt(2/dims[l-1])\n",
    "    parameters[\"b\"+ str(l)]=np.zeros(shape=(dims[l],1))\n",
    "    #limit=np.sqrt(6/(dims[l]+dims[l-1]))\n",
    "    # parameters[\"W\"+ str(l)]=np.random.uniform(-limit,limit,size=(dims[l],dims[l-1]))\n",
    "    # parameters[\"b\"+ str(l)]=np.random.uniform(-limit,limit,size=(dims[l],1))\n",
    "  return parameters\n",
    "\n",
    "def forward_activation(A,W,b,activation):\n",
    "  Z=W.dot(A)+b\n",
    "  if activation==\"relu\":\n",
    "    A_new=relu(Z)\n",
    "  elif activation==\"sigmoid\":\n",
    "    A_new=sigmoid(Z)\n",
    "  cache=((A,W,b),Z)\n",
    "  return A_new,cache\n",
    "\n",
    "def forward_propogate(X,parameters):\n",
    "  L=len(parameters)//2\n",
    "  caches=[]\n",
    "  A=X\n",
    "  for l in range(1,L):\n",
    "    A_prev=A\n",
    "    A,cache=forward_activation(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "  #Last layer\n",
    "  O,cache=forward_activation(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],\"sigmoid\")\n",
    "  caches.append(cache)\n",
    "  return O,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(O,Y,parameters,lambd):\n",
    "  assert(O.shape == Y.shape)\n",
    "  m=Y.shape[1]\n",
    "  #print(\"examples:\",m)\n",
    "  cost=(1./m)*(-np.dot(Y,np.log(O).T)-np.dot(1-Y,np.log(1-O).T))\n",
    "  cost=np.squeeze(cost)\n",
    "  assert(cost.shape==())\n",
    "  L=len(parameters)//2\n",
    "  reg_cost=0\n",
    "  for l in range(1,L+1):\n",
    "    reg_cost+=(1/m) * (lambd/2) * np.sum(parameters[\"W\"+str(l)]**2)\n",
    "  return cost#+reg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,v,grads,learning_rate):\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    beta=0.9\n",
    "    # Momentum update for each parameter\n",
    "    for l in range(L):\n",
    "        \n",
    "        ### START CODE HERE ### (approx. 4 lines)\n",
    "        # compute velocities\n",
    "        v[\"dW\" + str(l+1)] = beta * v[\"dW\" + str(l+1)] + (1-beta) * grads['dW' + str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta * v[\"db\" + str(l+1)] + (1-beta) * grads['db' + str(l+1)]\n",
    "        # update parameters\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v['dW' + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v['db' + str(l+1)]\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Back Propogation\n",
    "def relu_diff(da,z):\n",
    "  dz=da.copy()\n",
    "  dz[z<=0]=0\n",
    "  return dz\n",
    "def sigmoid_diff(da,z):\n",
    "  a=sigmoid(z)\n",
    "  dz=da*a*(1-a)\n",
    "  return dz\n",
    "\n",
    "def backward_activation(da,cache,activation):\n",
    "  cache1,cache2=cache\n",
    "  lambd=0.7\n",
    "  if activation==\"relu\":\n",
    "    dz=relu_diff(da,cache2)\n",
    "  elif activation==\"sigmoid\":\n",
    "    dz=sigmoid_diff(da,cache2)\n",
    "  a_prev,W,b=cache1\n",
    "  m=a_prev.shape[1]\n",
    "  da_prev=np.dot(W.T,dz)\n",
    "  dW=np.dot(dz,a_prev.T)*(1./m)#+(lambd/m) * W\n",
    "  db=np.sum(dz,axis=1,keepdims=True)*(1./m)\n",
    "  return da_prev,dW,db\n",
    "\n",
    "def back_propogate(O,Y,caches):\n",
    "  grads={}\n",
    "  m=O.shape[1]\n",
    "  L=len(caches)\n",
    "  Y=Y.reshape(O.shape)\n",
    "\n",
    "  dO=-(np.divide(Y,O)-np.divide(1-Y,1-O))\n",
    "  current_cache=caches[L-1]\n",
    "  grads[\"dA\"+str(L-1)],grads[\"dW\"+str(L)],grads[\"db\"+str(L)]=backward_activation(dO,current_cache,\"sigmoid\")\n",
    "\n",
    "  for l in reversed(range(L-1)):\n",
    "    current_cache=caches[l]\n",
    "    grads[\"dA\"+str(l)],grads[\"dW\"+str(l+1)],grads[\"db\"+str(l+1)]=backward_activation(grads[\"dA\"+str(l+1)],current_cache,\"sigmoid\")\n",
    "\n",
    "  return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,Y,parameters):\n",
    "  #print(X[:,[0,5,10]])\n",
    "  m=X.shape[1]\n",
    "  n=len(parameters)//2\n",
    "  predictions=np.zeros((1,m))\n",
    "  prob,cache=forward_propogate(X,parameters)\n",
    "  for i in range(0,prob.shape[1]):\n",
    "    if prob[0][i] > 0.5:\n",
    "        predictions[0][i]=1\n",
    "    else:\n",
    "        predictions[0][i]=0\n",
    "  #print(\"Accuracy: \"+str(np.sum(predictions[0]==Y[0])))\n",
    "  print(\"Accuracy: \"  + str(np.sum((predictions == Y)/m)))\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize velocity\n",
    "    for l in range(L):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v[\"dW\" + str(l+1)] = np.zeros_like(parameters['W' + str(l+1)])\n",
    "        v[\"db\" + str(l+1)] = np.zeros_like(parameters['b' + str(l+1)])\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,Y,layer_dims,learning_rate=0.0075,num_iterations=1500,print_cost=False):\n",
    "  parameters=init_parameters(layers_dims)\n",
    "  v=initialize_velocity(parameters)\n",
    "  costs=[]\n",
    "  for i in range(num_iterations):\n",
    "    O,caches=forward_propogate(X,parameters)\n",
    "    cost=compute_cost(O,Y,parameters,0.7)\n",
    "    grads=back_propogate(O,Y,caches)\n",
    "    parameters,v=update_parameters(parameters,v,grads,learning_rate)\n",
    "    #print(O,len(O[0]))\n",
    "    if print_cost and i%5000==0:\n",
    "      print(\"Cost after\",i,\"iteration:\",cost)\n",
    "      costs.append(cost)\n",
    "  \n",
    "\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 iteration: 0.5527827273533291\n",
      "Cost after 5000 iteration: 0.5394321022580177\n",
      "Cost after 10000 iteration: 0.530977806275594\n",
      "Cost after 15000 iteration: 0.5189626620191367\n",
      "Cost after 20000 iteration: 0.5024976158177745\n",
      "Cost after 25000 iteration: 0.48079770520985654\n",
      "Cost after 30000 iteration: 0.4530229978941102\n",
      "Cost after 35000 iteration: 0.41918190185574905\n",
      "Cost after 40000 iteration: 0.38198226227846754\n",
      "Cost after 45000 iteration: 0.3462620724549353\n",
      "Cost after 50000 iteration: 0.3159323347213807\n",
      "Cost after 55000 iteration: 0.2920890245939047\n",
      "Cost after 60000 iteration: 0.2738769523749869\n",
      "Cost after 65000 iteration: 0.2599738492156455\n",
      "Cost after 70000 iteration: 0.24930173542231732\n",
      "Cost after 75000 iteration: 0.24108873215058021\n",
      "Cost after 80000 iteration: 0.23474728135411504\n",
      "Cost after 85000 iteration: 0.22980021679347237\n",
      "Cost after 90000 iteration: 0.22586036605735713\n",
      "Cost after 95000 iteration: 0.2226209791757344\n"
     ]
    }
   ],
   "source": [
    "layers_dims=(len(df.columns) - 1,32,8,1)\n",
    "parameters=model(X_train.T,y_train.reshape((1,len(y_train))),layers_dims,learning_rate=0.005,num_iterations=100000,print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9402985074626866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_train.T,y_train.reshape((1,len(y_train))),parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8620689655172412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test.T,y_test.reshape((1,len(y_test))),parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-7.69610223e-01,  5.50910983e-04, -4.89872916e-01,\n",
       "         -1.44838322e+00,  2.10026257e-01,  1.67500000e-01,\n",
       "          1.78509742e-01, -1.25782060e+00,  2.89832092e-01],\n",
       "        [ 5.69498951e-01, -2.66568401e-01,  2.14071387e-01,\n",
       "          3.23548730e-01, -9.46196910e-02,  3.39153566e-01,\n",
       "          7.08353004e-02,  1.97206397e-01,  1.74816400e-01],\n",
       "        [ 4.24806611e-01, -5.03044697e-01, -4.91106477e-01,\n",
       "         -9.96669668e-02,  5.43265759e-01, -1.95661490e-01,\n",
       "          1.29506484e+00,  4.01513417e-01, -1.06969626e-01],\n",
       "        [-2.91850002e-01, -1.18603375e+00, -7.47234522e-01,\n",
       "          5.24718277e-01, -5.23838514e-01,  8.61335147e-03,\n",
       "          6.87946557e-01,  8.56351949e-01, -2.13761781e-02],\n",
       "        [ 1.75279327e-01,  4.01215410e+00,  8.41826027e-02,\n",
       "         -3.48382999e-01, -2.39224769e-01,  4.88864997e-02,\n",
       "          3.76205672e-01, -2.84159195e-01, -5.54783633e-01],\n",
       "        [ 2.07186566e-01,  4.60026569e-01,  6.33173071e-01,\n",
       "         -9.15062239e-01,  5.28868747e-01,  5.67339858e-02,\n",
       "         -3.73431726e-01, -1.88298642e-02,  1.39659401e+00],\n",
       "        [-4.30104365e-01, -3.34741369e-02,  5.54744891e-01,\n",
       "          1.02494698e-02, -1.32115430e-02,  4.05422613e-02,\n",
       "         -2.43586982e-01,  2.13109562e-01, -1.86811353e-01],\n",
       "        [-4.59936128e-01, -1.15880003e+00, -1.29504100e-01,\n",
       "         -3.24444895e-02,  2.12501761e-01,  4.74302835e-02,\n",
       "         -2.55460425e-01,  1.75208573e-01, -4.46353123e-01],\n",
       "        [-2.86771073e-01, -3.47549022e-01,  7.99215844e-01,\n",
       "         -6.53546345e-01, -1.66971216e-01,  1.49479210e-01,\n",
       "         -3.29051071e-01,  6.44963874e-01, -2.99352174e-01],\n",
       "        [ 1.21274605e+00,  2.51055982e-01,  8.01662120e-02,\n",
       "          8.06519555e-01,  3.34737514e-01,  2.53172746e-02,\n",
       "          6.03811709e-01, -9.78776733e-01, -3.24077878e-01],\n",
       "        [ 2.66704410e-01, -7.60704395e-02,  2.95687401e-01,\n",
       "         -4.13835462e-01, -9.58401472e-02,  6.79300954e-01,\n",
       "         -5.69025186e-02,  4.83198746e-01, -2.85878211e-01],\n",
       "        [ 4.07455396e-02, -1.72440147e+00,  8.07881330e-01,\n",
       "         -1.25537499e-01,  3.68940557e-01, -3.95757235e-02,\n",
       "          6.36239888e-02,  5.91535701e-02, -6.25711374e-01],\n",
       "        [ 2.46205995e-01,  1.25643150e+00,  8.16840362e-01,\n",
       "          2.27835597e-01,  1.01855791e+00, -7.02592453e-01,\n",
       "         -2.31421720e-01, -2.87834135e-02, -2.35103364e-01],\n",
       "        [ 3.58809525e-01,  6.12025323e-01,  9.34404770e-01,\n",
       "         -6.78975816e-02,  4.22858601e-01,  6.05182418e-01,\n",
       "         -9.45139931e-02,  6.14156848e-01,  6.81793650e-01],\n",
       "        [ 2.14617975e-01,  6.09925635e-01, -6.22543883e-01,\n",
       "         -4.86294355e-01,  1.91023593e-01,  7.42549765e-01,\n",
       "         -6.63294155e-01, -4.15388083e-01, -7.31923653e-02],\n",
       "        [ 4.86379921e-01,  7.18786238e-01,  1.01647919e-01,\n",
       "         -8.54966432e-02,  1.39849328e-01, -3.60537994e-01,\n",
       "          4.06996817e-01, -2.75819218e-01,  2.41835909e-01],\n",
       "        [-7.00133878e-01, -1.33515158e+00, -1.20144813e-01,\n",
       "          3.03006297e-01,  3.53800066e-01, -9.29018160e-01,\n",
       "         -6.99059619e-01, -4.60529997e-01,  3.96094067e-01],\n",
       "        [ 6.06969972e-02,  3.92423995e-01, -2.62533298e-01,\n",
       "         -7.88673361e-01,  1.55277502e-01,  3.16702383e-01,\n",
       "          1.43961325e-01, -4.71765621e-01,  1.16701134e-02],\n",
       "        [ 6.19085687e-01, -4.79911241e-01, -2.21881991e-01,\n",
       "          2.37052501e-01, -7.69958388e-01, -1.03183537e-01,\n",
       "         -5.18190510e-01, -3.80327015e-01, -4.30182230e-01],\n",
       "        [ 3.19285806e-01,  4.75452607e-02, -3.98312718e-01,\n",
       "         -2.73257193e-01, -3.21959149e-01, -2.68106599e-01,\n",
       "          7.95523993e-03, -2.34603315e-01, -1.01963646e-01],\n",
       "        [ 8.19998267e-02,  2.04086568e+00, -5.74579159e-01,\n",
       "          2.43389559e-01, -2.94651578e-01, -3.87483105e-01,\n",
       "          2.83103873e-01, -2.41080439e-01, -2.56630029e-01],\n",
       "        [ 2.81050307e-01, -1.64548190e+00, -5.82115582e-01,\n",
       "         -1.40653164e-02,  6.81388750e-01,  2.37099549e-01,\n",
       "         -4.39326780e-01, -1.40119741e-02,  2.13166002e-01],\n",
       "        [-3.02970710e-01, -1.95681154e-01, -4.63210849e-01,\n",
       "          6.08706651e-01,  1.80774729e-01,  1.53816870e-01,\n",
       "          6.23592588e-01, -7.41592007e-01,  9.22076782e-01],\n",
       "        [ 6.59279721e-01, -2.02956474e+00, -1.60539278e-01,\n",
       "         -1.63479403e-01,  4.60837750e-02,  4.69846619e-01,\n",
       "         -4.85561768e-01, -5.98301873e-01, -2.96357424e-01],\n",
       "        [-9.07371320e-01, -1.25037178e+00, -2.44119432e-01,\n",
       "         -3.13848513e-01, -2.36632800e-01,  3.35148952e-01,\n",
       "         -6.48930296e-02, -6.08654570e-01, -1.63747886e-01],\n",
       "        [-1.47281800e-01, -1.67107173e-01, -9.90370333e-02,\n",
       "         -8.22998717e-01, -2.16684713e-01,  5.79300710e-01,\n",
       "         -8.01332617e-02, -4.16906928e-01, -7.75999038e-02],\n",
       "        [ 5.97955519e-01,  1.62865933e+00, -4.67513746e-01,\n",
       "          2.39125169e-01, -3.19168997e-01,  2.83119465e-01,\n",
       "         -8.96222698e-02,  4.16291561e-01, -4.33359229e-01],\n",
       "        [ 1.27655608e-01,  1.73330195e+00,  5.88778331e-01,\n",
       "         -3.04561855e-01, -1.39253630e-01,  1.18277705e-01,\n",
       "          3.21450424e-01, -4.27725755e-01,  1.05813211e-01],\n",
       "        [-7.20596553e-01, -2.91966619e+00,  4.57732247e-01,\n",
       "         -7.28774750e-02,  1.93482387e-01,  2.44812491e-01,\n",
       "          1.96823680e-01,  1.14700279e-01,  1.27743038e-03],\n",
       "        [ 3.22122142e-01,  1.76215878e-01,  6.34562053e-02,\n",
       "         -2.50488317e-01, -8.39421039e-01,  5.62486411e-03,\n",
       "         -5.16128573e-02,  3.89555544e-01, -8.10664984e-01],\n",
       "        [ 5.34199212e-01,  3.37972615e-01,  1.51322894e-01,\n",
       "         -6.47857520e-01, -6.32310675e-01,  7.25881619e-01,\n",
       "          5.49783067e-01, -1.35182406e-01,  4.97931816e-01],\n",
       "        [ 5.35787020e-01,  2.10135316e+00, -3.43842345e-02,\n",
       "         -1.57404071e-01, -2.16760862e-01,  3.17667965e-01,\n",
       "         -2.05985004e-01,  2.10259236e-03, -2.78042332e-01]]),\n",
       " 'b1': array([[ 0.02953638],\n",
       "        [ 0.00927055],\n",
       "        [ 0.15870349],\n",
       "        [-0.03951565],\n",
       "        [-0.46549261],\n",
       "        [-0.00551687],\n",
       "        [ 0.01905125],\n",
       "        [ 0.2495545 ],\n",
       "        [ 0.15256394],\n",
       "        [-0.02132368],\n",
       "        [ 0.04873147],\n",
       "        [-0.08092726],\n",
       "        [-0.28898585],\n",
       "        [ 0.02164197],\n",
       "        [-0.08590143],\n",
       "        [-0.08786581],\n",
       "        [ 0.36508205],\n",
       "        [ 0.01247131],\n",
       "        [ 0.05169533],\n",
       "        [-0.00685239],\n",
       "        [ 0.24913208],\n",
       "        [-0.01861054],\n",
       "        [ 0.06929607],\n",
       "        [ 0.34186489],\n",
       "        [ 0.35712531],\n",
       "        [ 0.01633754],\n",
       "        [-0.18371042],\n",
       "        [-0.2782804 ],\n",
       "        [ 0.33656201],\n",
       "        [ 0.01290408],\n",
       "        [-0.00499112],\n",
       "        [-0.62456513]]),\n",
       " 'W2': array([[-1.01817934e-01, -1.84492902e-01, -1.44069385e-01,\n",
       "         -4.71452308e-01,  2.00991843e+00,  4.63259833e-01,\n",
       "          5.08933764e-01, -5.24100223e-01, -3.48362107e-01,\n",
       "          5.68865127e-02, -4.46126716e-01, -1.16611918e+00,\n",
       "          6.21793030e-01, -2.43331007e-01,  7.93744140e-01,\n",
       "          3.94188073e-02, -7.87466467e-01, -1.27433703e-01,\n",
       "         -9.06854810e-02, -2.19688524e-01,  1.12163060e+00,\n",
       "         -7.95002720e-01, -2.62444299e-01, -1.22244151e+00,\n",
       "         -6.31961112e-01,  1.46475616e-03,  6.65972045e-01,\n",
       "          7.20342523e-01, -1.59232036e+00,  8.83520590e-03,\n",
       "          7.77385295e-02,  1.08536805e+00],\n",
       "        [ 3.33869738e-01, -3.78171419e-02,  3.04192579e-01,\n",
       "          4.80999043e-01, -1.85723298e+00, -5.53172949e-02,\n",
       "          4.34248124e-01,  7.10849592e-01,  7.66786794e-02,\n",
       "          1.55726056e-01, -1.33038036e-01,  7.25180713e-01,\n",
       "         -3.35218371e-01, -1.88454763e-01, -1.44965837e-01,\n",
       "         -3.14729851e-01,  5.56211418e-01, -8.89195988e-02,\n",
       "          4.59581242e-01, -3.42889735e-01, -7.60817739e-01,\n",
       "          9.27247336e-01,  1.56812137e-01,  7.65196925e-01,\n",
       "          1.85537608e-01, -2.68101154e-01, -6.46792668e-01,\n",
       "         -8.13837720e-01,  1.30555942e+00, -4.22334452e-02,\n",
       "          2.91505610e-01, -7.05986515e-01],\n",
       "        [ 5.27494067e-01,  1.65051936e-01,  6.10559372e-02,\n",
       "         -9.59770089e-02, -1.00814869e+00,  2.43895254e-01,\n",
       "          4.33459637e-01,  2.40607348e-01,  3.31584866e-01,\n",
       "         -3.60056217e-01, -2.47299997e-01,  1.48900466e-01,\n",
       "         -4.43928071e-01,  3.41514349e-01,  2.14322636e-01,\n",
       "         -1.31391099e-01, -5.47410302e-02, -5.29894665e-01,\n",
       "          2.97355376e-01,  3.49713977e-01, -5.03824633e-01,\n",
       "          2.18351817e-01,  1.43488727e-01,  5.18905488e-02,\n",
       "          3.99966980e-01,  2.56995905e-01, -1.39274666e-01,\n",
       "         -3.93901253e-01,  6.91319625e-01,  4.74694607e-01,\n",
       "          1.43897785e-01, -3.06448447e-01],\n",
       "        [-4.99796929e-01,  1.73342584e-01, -3.23352632e-01,\n",
       "         -9.84149627e-01,  1.73827494e+00,  2.98005608e-01,\n",
       "         -2.43605433e-01, -4.06160120e-01, -4.04104568e-01,\n",
       "         -2.48358886e-01, -5.70228448e-02, -9.52926877e-01,\n",
       "          4.88937390e-01,  1.70232761e-01,  1.52724373e-01,\n",
       "          9.31617779e-01, -7.16280327e-01,  2.55334080e-01,\n",
       "         -3.27930654e-01, -2.76023877e-01,  8.59616939e-01,\n",
       "         -5.73283368e-01,  5.28981573e-02, -8.28442619e-01,\n",
       "         -7.62990452e-01, -3.48533178e-01,  3.03794528e-01,\n",
       "          7.07991474e-01, -1.78111546e+00,  2.28998487e-01,\n",
       "          4.24781549e-01,  6.74270102e-01],\n",
       "        [-5.86674269e-01,  3.05291725e-01, -4.19028189e-01,\n",
       "         -3.65410153e-01,  3.91608446e-01, -2.30074475e-01,\n",
       "         -1.83737668e-01, -5.57645039e-01, -6.00667120e-01,\n",
       "         -3.54433440e-01,  1.59534483e-01, -4.89899401e-01,\n",
       "          4.00787054e-01,  2.92327485e-01,  5.34454096e-01,\n",
       "         -2.43977502e-01, -4.08337191e-01,  5.72883331e-02,\n",
       "         -9.52060958e-02, -6.14546256e-02,  3.12742505e-01,\n",
       "         -7.05978452e-02,  4.22269110e-02, -5.55164684e-01,\n",
       "         -8.95709420e-01,  2.45423687e-01,  5.11416527e-01,\n",
       "          7.03785904e-01, -8.55849144e-01,  1.90298784e-01,\n",
       "          3.48333788e-01,  5.66534851e-01],\n",
       "        [-2.87761199e-01, -2.84506520e-01, -5.71283956e-01,\n",
       "         -6.14145064e-01,  2.02977231e+00,  2.17283270e-01,\n",
       "         -3.21804366e-01, -5.24847166e-01, -1.42660377e-01,\n",
       "         -4.63643087e-02, -4.72286887e-01, -6.07664752e-01,\n",
       "          4.13097515e-01,  3.85206661e-01, -3.25187762e-02,\n",
       "          2.19028359e-01, -3.69388353e-01,  2.51056735e-01,\n",
       "         -1.09098041e-01,  1.41433410e-01,  8.54908161e-01,\n",
       "         -6.67294711e-01, -1.70440821e-01, -7.77863955e-01,\n",
       "         -7.68477421e-01, -3.55260815e-01,  8.96682119e-01,\n",
       "          6.73312276e-01, -1.21061741e+00, -3.83751579e-01,\n",
       "          1.78878257e-01,  1.02501403e+00],\n",
       "        [-6.83631293e-02,  8.14345914e-02, -1.44488220e-01,\n",
       "          3.20543011e-01, -6.22029171e-01, -2.04231948e-01,\n",
       "         -2.51087266e-01,  4.06708695e-01,  2.78283733e-01,\n",
       "         -3.24509277e-02,  5.29725944e-02,  2.48580180e-01,\n",
       "          6.16643929e-02,  4.34187693e-01, -1.59092575e-01,\n",
       "          9.59765415e-02,  2.53865265e-01,  4.87417066e-01,\n",
       "          2.04587867e-01, -3.28517864e-01,  9.88046622e-02,\n",
       "          3.07864288e-01, -3.09214457e-03,  8.39426041e-01,\n",
       "          1.59894743e-01,  2.59420276e-01, -4.78320816e-01,\n",
       "         -6.53483172e-02, -1.21202834e-01, -1.16157926e-01,\n",
       "         -6.60093218e-02, -4.24286031e-01],\n",
       "        [ 1.24201361e-01,  2.90872781e-01, -8.92904599e-03,\n",
       "          1.62251240e-01, -1.49943136e-01,  1.52102657e-01,\n",
       "         -2.61285360e-01,  1.59875793e-01, -5.84662619e-01,\n",
       "          2.82587115e-01, -7.35224339e-03, -2.47049730e-01,\n",
       "         -6.25546502e-02,  5.22074704e-01,  8.05526308e-02,\n",
       "          1.72174153e-01,  3.29787841e-01,  2.58335591e-01,\n",
       "          3.08619265e-01,  1.20598021e-01,  1.06078141e-01,\n",
       "          3.38359535e-01, -2.51994658e-02,  3.60726216e-01,\n",
       "         -4.03357322e-02,  3.12519193e-01, -2.09814409e-01,\n",
       "         -3.89591854e-01,  3.66046224e-01, -4.00167360e-01,\n",
       "         -2.71863552e-01, -1.73176107e-01]]),\n",
       " 'b2': array([[-0.26381217],\n",
       "        [ 0.27337625],\n",
       "        [ 0.15175117],\n",
       "        [-0.10741869],\n",
       "        [-0.1222118 ],\n",
       "        [-0.23998888],\n",
       "        [ 0.07632144],\n",
       "        [ 0.08330156]]),\n",
       " 'W3': array([[ 3.87144912, -3.6662399 , -1.85455392,  3.38838202,  1.681614  ,\n",
       "          3.28820872, -1.44690004, -0.92284551]]),\n",
       " 'b3': array([[-1.06321827]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
