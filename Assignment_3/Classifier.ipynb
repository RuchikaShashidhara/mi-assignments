{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset using Pandas\n",
    "df = pd.read_csv(\"LBW_Dataset.csv\")\n",
    "\n",
    "# Normalization & Scaling Functions using Numpy & Pandas\n",
    "\n",
    "# Outlier Scaling using .quantile() Pandas methods\n",
    "def scale_outlier(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    min_bound = Q1 - 1.5*IQR\n",
    "    max_bound = Q3 + 1.5*IQR\n",
    "    df[column] = np.where(df[column] > max_bound, max_bound, df[column])\n",
    "    df[column] = np.where(df[column] < min_bound, min_bound, df[column])\n",
    "\n",
    "# Min-Max Scaling using .min() and .max() Pandas methods\n",
    "def min_max_scaling(df):    \n",
    "    df_norm = df.copy()\n",
    "    for column in df_norm.columns:\n",
    "        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())        \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Drop the columns Delivery Phase(1: 90, 2: 2, NaN: 4) and Education(5: 93, NaN: 3)\n",
    "df = df.drop([\"Delivery phase\", \"Education\", \"Community\"], axis = 1)\n",
    "\n",
    "# Replacing Nan of Weights with the Mean of its respective Result category\n",
    "mean_0 = (df.loc[df['Result'] == 0])['Weight'].mean()\n",
    "mean_1 = (df.loc[df['Result'] == 1])['Weight'].mean()\n",
    "\n",
    "df[\"Weight\"] = np.where((df[\"Result\"] == 0) & (df[\"Weight\"].isna()), mean_0, df[\"Weight\"])\n",
    "df[\"Weight\"] = np.where((df[\"Result\"] == 1) & (df[\"Weight\"].isna()), mean_1, df[\"Weight\"])\n",
    "\n",
    "# For now, Filling Numeric Columned NaN Values with Mean\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "df[\"HB\"] = df[\"HB\"].fillna(df[\"HB\"].mean())\n",
    "df[\"BP\"] = df[\"BP\"].fillna(df[\"BP\"].mean())\n",
    "\n",
    "# Very Basic Method of taking care of Outliers(Replace with IQR, Min-Max) for Age & BP columns\n",
    "scale_outlier(df, \"Age\")\n",
    "scale_outlier(df, \"BP\")\n",
    "\n",
    "# Labelling Residence = 2 as Residence = 0 to get Binary Labelled Column (Before: Residence(1,2), After: Residence(1,0))\n",
    "df[\"Residence\"] = np.where(df[\"Residence\"] == 2, 0, df[\"Residence\"])\n",
    "# Filling NaN with Mode = 1\n",
    "df[\"Residence\"] = df[\"Residence\"].fillna(1)\n",
    "\n",
    "# Converting IFA(int) to IFA(float)\n",
    "df[\"IFA\"] = df[\"IFA\"].astype(float)\n",
    "\n",
    "# Moving converted Float Result, to get it as the last Column\n",
    "res = df[\"Result\"].astype(float)\n",
    "df = df.drop([\"Result\"], axis = 1)\n",
    "df[\"Result\"] = res\n",
    "\n",
    "# Performing Normalization of the dataset (into ranges from 0 to 1) using Pandas\n",
    "df = min_max_scaling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train-Test Splits of the dataset using .train_test_split() in Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return [1 / (1 + math.exp(-ele)) for ele in x ]\n",
    "\n",
    "class layer():\n",
    "    def __init__(self, input_units, output_units, alpha = 0.00001, activation = 'tanh'):\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.weights = np.random.normal(loc=0.0, \n",
    "                                        scale = np.sqrt(2/(input_units+output_units)), \n",
    "                                        size = (input_units,output_units))\n",
    "        self.bias = np.zeros(output_units)\n",
    "        self.input = np.zeros(output_units)\n",
    "        self.activated_output = np.zeros(output_units)\n",
    "        \n",
    "        # adam optimiser : parameters\n",
    "        self.alpha = alpha\n",
    "        self.t = 0\n",
    "        self.m = 0\n",
    "        self.v = 0;\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.99\n",
    "        self.epsilon = 1e-8\n",
    "        \n",
    "    def forward_prop(self, inputs):\n",
    "        self.input = inputs\n",
    "        forward_units = np.dot(inputs, self.weights) + self.bias\n",
    "        \n",
    "        if self.activation == 'tanh':\n",
    "            self.activated_output = np.tanh(forward_units)\n",
    "            \n",
    "        elif self.activation == 'relu':\n",
    "            self.activated_output = np.maximum(0, forward_units)\n",
    "            \n",
    "        elif self.activation == 'logistic':\n",
    "            self.activated_output = sigmoid(forward_units)\n",
    "            \n",
    "        elif self.activation == 'identity':\n",
    "            self.activated_output = forward_units\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def update_weights(self, grad):\n",
    "        # adam optimiser\n",
    "        grad = grad.reshape(self.weights.shape)\n",
    "        self.m = self.beta_1*self.m + grad*(1-self.beta_1)\n",
    "        self.v = self.beta_2*self.v + np.square(grad)*(1-self.beta_2)\n",
    "        self.t += 1\n",
    "        \n",
    "        m_hat = self.m/(1 - pow(self.beta_1, self.t))\n",
    "        v_hat = self.v/(1 - pow(self.beta_2, self.t))\n",
    "        tmp = self.alpha*(m_hat/(v_hat + self.epsilon))\n",
    "                          \n",
    "        self.weights = self.weights - tmp           \n",
    "    \n",
    "    def loss_function(self, target):\n",
    "        return [-(target*math.log(ele) + (1-target)*math.log(1-ele)) for ele in self.activated_output]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_units = 6\n",
    "output_units = 1\n",
    "hidden_layer1_units = 20\n",
    "\n",
    "classifier = []\n",
    "classifier.append(layer(input_units, hidden_layer1_units))\n",
    "classifier.append(layer(hidden_layer1_units, output_units, activation = 'logistic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind, inputs in enumerate(X_train):\n",
    "    inputs = X_train[ind]\n",
    "    outputs = y_train[ind]\n",
    "    for layer in classifier:\n",
    "        inputs = layer.forward_prop(inputs)\n",
    "\n",
    "    prediction = inputs\n",
    "\n",
    "    output_layer = classifier[1]\n",
    "    grad = gradient_sigmoid(prediction, output_layer.input, outputs)    \n",
    "    output_layer.update_weights(grad)\n",
    "    \n",
    "#     hidden_layer = classifier[0]\n",
    "#     grad = gradient_tanh()\n",
    "#     hidden_layer.update_weights(grad)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_sigmoid(z, A, y):\n",
    "    grad = (z-y)*A\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_tanh():\n",
    "    # have to complete\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, inputs in enumerate(X_train):\n",
    "    outputs = y_train[ind]\n",
    "    for layer in classifier:\n",
    "        inputs = layer.forward_prop(inputs)\n",
    "        \n",
    "    prediction = inputs\n",
    "#     print(prediction, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
