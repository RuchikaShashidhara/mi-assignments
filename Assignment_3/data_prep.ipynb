{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n",
      "1.19.2\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check if proper versions are used\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization & Scaling Functions using Numpy & Pandas\n",
    "\n",
    "# Outlier Scaling using .quantile() Pandas methods\n",
    "def scale_outlier(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    min_bound = Q1 - 1.5*IQR\n",
    "    max_bound = Q3 + 1.5*IQR\n",
    "    df[column] = np.where(df[column] > max_bound, max_bound, df[column])\n",
    "    df[column] = np.where(df[column] < min_bound, min_bound, df[column])\n",
    "\n",
    "# Min-Max Scaling using .min() and .max() Pandas methods\n",
    "def min_max_scaling(df):    \n",
    "    df_norm = df.copy()\n",
    "    for column in df_norm.columns:\n",
    "        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())        \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset using Pandas\n",
    "df = pd.read_csv(\"LBW_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Drop the columns Delivery Phase(1: 90, 2: 2, NaN: 4) and Education(5: 93, NaN: 3)\n",
    "df = df.drop([\"Delivery phase\", \"Education\", \"Community\"], axis = 1)\n",
    "\n",
    "# Not sure if this is Proper, what if testing set has Community = 2?\n",
    "# Replacing Community = 2(count = 1) with Community = 1\n",
    "# df[\"Community\"] = np.where(df[\"Community\"] == 2, 1, df[\"Community\"])ss\n",
    "\n",
    "# Replacing Nan of Weights with the Mean of its respective Result category\n",
    "mean_0 = (df.loc[df['Result'] == 0])['Weight'].mean()\n",
    "mean_1 = (df.loc[df['Result'] == 1])['Weight'].mean()\n",
    "\n",
    "df[\"Weight\"] = np.where((df[\"Result\"] == 0) & (df[\"Weight\"].isna()), mean_0, df[\"Weight\"])\n",
    "df[\"Weight\"] = np.where((df[\"Result\"] == 1) & (df[\"Weight\"].isna()), mean_1, df[\"Weight\"])\n",
    "\n",
    "# For now, Filling Numeric Columned NaN Values with Mean\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "df[\"HB\"] = df[\"HB\"].fillna(df[\"HB\"].mean())\n",
    "df[\"BP\"] = df[\"BP\"].fillna(df[\"BP\"].mean())\n",
    "# df[\"Weight\"] = df[\"Weight\"].fillna(df[\"Weight\"].mean()) -> cleaned using the above method\n",
    "\n",
    "# Very Basic Method of taking care of Outliers(Replace with IQR, Min-Max) for Age & BP columns\n",
    "scale_outlier(df, \"Age\")\n",
    "scale_outlier(df, \"BP\")\n",
    "\n",
    "# Labelling Residence = 2 as Residence = 0 to get Binary Labelled Column (Before: Residence(1,2), After: Residence(1,0))\n",
    "df[\"Residence\"] = np.where(df[\"Residence\"] == 2, 0, df[\"Residence\"])\n",
    "# Filling NaN with Mode = 1\n",
    "df[\"Residence\"] = df[\"Residence\"].fillna(1)\n",
    "\n",
    "# One-Hot-Encode Community(1,3,4) to Community_1(1,0), Community_3(1,0), Community_4(1,0)\n",
    "# df = pd.get_dummies(df, columns=[\"Community\"], dtype = float)\n",
    "\n",
    "# Converting IFA(int) to IFA(float)\n",
    "df[\"IFA\"] = df[\"IFA\"].astype(float)\n",
    "\n",
    "# Moving converted Float Result, to get it as the last Column\n",
    "res = df[\"Result\"].astype(float)\n",
    "df = df.drop([\"Result\"], axis = 1)\n",
    "df[\"Result\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Normalization of the dataset (into ranges from 0 to 1) using Pandas\n",
    "df = min_max_scaling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>HB</th>\n",
       "      <th>IFA</th>\n",
       "      <th>BP</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.452382</td>\n",
       "      <td>0.402381</td>\n",
       "      <td>0.622867</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.358478</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.185433</td>\n",
       "      <td>0.235995</td>\n",
       "      <td>0.138207</td>\n",
       "      <td>0.465946</td>\n",
       "      <td>0.199033</td>\n",
       "      <td>0.343964</td>\n",
       "      <td>0.435286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.478632</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.622867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age     Weight         HB        IFA         BP  Residence  \\\n",
       "count  96.000000  96.000000  96.000000  96.000000  96.000000  96.000000   \n",
       "mean    0.452382   0.402381   0.622867   0.687500   0.358478   0.864583   \n",
       "std     0.185433   0.235995   0.138207   0.465946   0.199033   0.343964   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.273504   0.257143   0.607843   0.000000   0.171030   1.000000   \n",
       "50%     0.478632   0.342857   0.622867   1.000000   0.363002   1.000000   \n",
       "75%     0.564103   0.550000   0.647059   1.000000   0.502618   1.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "          Result  \n",
       "count  96.000000  \n",
       "mean    0.750000  \n",
       "std     0.435286  \n",
       "min     0.000000  \n",
       "25%     0.750000  \n",
       "50%     1.000000  \n",
       "75%     1.000000  \n",
       "max     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train-Test Splits of the dataset using .train_test_split() in Sklearn\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,10), activation='tanh', solver='adam', learning_rate = 'constant'\\\n",
    "                    , alpha = 0.00001, max_iter = 20000, random_state = 0)\n",
    "mlp.out_activation_ = 'tanh'\n",
    "mlp.fit(X_train,y_train.ravel())\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "print(predict_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 441\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "print(mlp.n_outputs_, mlp.n_layers_, mlp.n_iter_)\n",
    "print(len(predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  5]\n",
      " [ 3 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.77      0.81        22\n",
      "         1.0       0.90      0.94      0.92        50\n",
      "\n",
      "    accuracy                           0.89        72\n",
      "   macro avg       0.88      0.86      0.87        72\n",
      "weighted avg       0.89      0.89      0.89        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_train,predict_train))\n",
    "print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         2\n",
      "         1.0       1.00      0.91      0.95        22\n",
      "\n",
      "    accuracy                           0.92        24\n",
      "   macro avg       0.75      0.95      0.81        24\n",
      "weighted avg       0.96      0.92      0.93        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  5]\n",
      " [ 5 67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.79      0.79        24\n",
      "         1.0       0.93      0.93      0.93        72\n",
      "\n",
      "    accuracy                           0.90        96\n",
      "   macro avg       0.86      0.86      0.86        96\n",
      "weighted avg       0.90      0.90      0.90        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_total = mlp.predict(X)\n",
    "print(confusion_matrix(y,predict_total))\n",
    "print(classification_report(y,predict_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
